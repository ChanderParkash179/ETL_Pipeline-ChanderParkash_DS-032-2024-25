{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install packages from requirements.txt\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAVs1L9679rv",
        "outputId": "9ca8fd2d-8ba6-447b-b7a9-c73b4bd44ed1"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (2.2.2)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (0.3.11)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (4.11.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (0.13.2)\n",
            "Requirement already satisfied: faker in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (37.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->-r requirements.txt (line 1)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->-r requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->-r requirements.txt (line 1)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->-r requirements.txt (line 1)) (2025.1.31)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 2)) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 2)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 2)) (2025.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from kagglehub->-r requirements.txt (line 3)) (24.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from kagglehub->-r requirements.txt (line 3)) (6.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kagglehub->-r requirements.txt (line 3)) (4.67.1)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from pymongo->-r requirements.txt (line 4)) (2.7.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 5)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 5)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 5)) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 5)) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 5)) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 5)) (3.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 2)) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "EI8Q2WDu2Gd1"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter\n",
        "from pymongo import MongoClient\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import subprocess\n",
        "import faker\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "try:\n",
        "    result = subprocess.run([\"python3\", \"/content/load_to_db.py\"], check=True, capture_output=True, text=True)\n",
        "    print(\"‚úÖ Script executed successfully!\\n\")\n",
        "    print(result.stdout)\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(\"‚ùå Failed to run load_to_db.py\")\n",
        "    print(\"üîç Error Output:\\n\", e.stderr)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IF6khsRLGOjW",
        "outputId": "d25d9798-7169-420b-868a-39596fee0817"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Script executed successfully!\n",
            "\n",
            "‚úÖ Connected to MongoDB!\n",
            "üìÇ Database: sports_data, Collection: sports_data\n",
            "üî¢ Existing Documents: 0\n",
            "‚ùå Failed to connect or insert into MongoDB.\n",
            "üîç Error: batch op errors occurred, full error: {'writeErrors': [{'index': 1000, 'code': 11000, 'errmsg': \"E11000 duplicate key error collection: sports_data.sports_data index: _id_ dup key: { _id: ObjectId('67f0f62e70291b38f4b2e680') }\", 'keyPattern': {'_id': 1}, 'keyValue': {'_id': ObjectId('67f0f62e70291b38f4b2e680')}, 'op': {'ID': 1820, 'Name': 'Edward Conrad', 'Team': 'Eagles', 'Sport': 'Football', 'Nationality': 'USA', '_id': ObjectId('67f0f62e70291b38f4b2e680')}}], 'writeConcernErrors': [], 'nInserted': 1000, 'nUpserted': 0, 'nMatched': 0, 'nModified': 0, 'nRemoved': 0, 'upserted': []}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract data from CSV\n",
        "def extract_csv(file_path):\n",
        "    print(f\"‚ùØ Extracting CSV from {file_path}...\")\n",
        "    return pd.read_csv(file_path).to_dict(orient=\"records\")\n",
        "\n",
        "# Function to extract data from JSON\n",
        "def extract_json(file_path):\n",
        "    print(f\"‚ùØ Extracting JSON from {file_path}...\")\n",
        "    with open(file_path, \"r\") as f:\n",
        "        return json.load(f)\n",
        "\n",
        "# Function to extract data from Excel\n",
        "def extract_excel(file_path):\n",
        "    print(f\"‚ùØ Extracting Excel from {file_path}...\")\n",
        "    return pd.read_excel(file_path).to_dict(orient=\"records\")\n",
        "\n",
        "# Function to extract data from MongoDB collection\n",
        "def extract_mongodb(mongo_uri, db_name, collection_name):\n",
        "    print(f\"‚ùØ Extracting data from MongoDB...\")\n",
        "    client = MongoClient(mongo_uri)\n",
        "    db = client[db_name]\n",
        "    collection = db[collection_name]\n",
        "    return list(collection.find())"
      ],
      "metadata": {
        "id": "KO_sEkqdINIX"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to transform the data (e.g., cleaning or adding new fields)\n",
        "def transform_data(data):\n",
        "    print(f\"‚ùØ Transforming data...\")\n",
        "\n",
        "    # Remove duplicates based on Name & Country or Name & Sport\n",
        "    seen_records = set()\n",
        "    cleaned_data = []\n",
        "\n",
        "    for record in data:\n",
        "        name = record.get(\"Name\", \"\").strip()\n",
        "        country = record.get(\"Country\", \"\").strip()\n",
        "        sport = record.get(\"Sport\", \"\").strip()\n",
        "\n",
        "        # Create composite keys based on (Name & Country) or (Name & Sport)\n",
        "        if (name, country) not in seen_records and (name, sport) not in seen_records:\n",
        "            seen_records.add((name, country))\n",
        "            seen_records.add((name, sport))\n",
        "            cleaned_data.append(record)\n",
        "\n",
        "    # Apply transformations like cleaning, unit conversions, etc.\n",
        "    transformed_data = []\n",
        "    for record in cleaned_data:\n",
        "        # Data Cleaning: Handle missing values and erroneous values\n",
        "        if 'Sport' not in record or not record['Sport']:\n",
        "            record['Sport'] = 'Unknown'\n",
        "        if 'Team' not in record or not record['Team']:\n",
        "            record['Team'] = 'Unknown'\n",
        "\n",
        "        transformed_data.append(record)\n",
        "\n",
        "    return transformed_data"
      ],
      "metadata": {
        "id": "-OKW29rnIVHF"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load data into MongoDB\n",
        "def load_to_mongodb(mongo_uri, db_name, collection_name, data):\n",
        "    print(f\"‚ùØ Loading data into MongoDB collection '{collection_name}'...\")\n",
        "\n",
        "    # Connect to MongoDB\n",
        "    client = MongoClient(mongo_uri)\n",
        "\n",
        "    # Access the database (MongoDB will create it if it doesn't exist)\n",
        "    db = client[db_name]\n",
        "\n",
        "    # Access the collection (MongoDB will create it if it doesn't exist)\n",
        "    collection = db[collection_name]\n",
        "\n",
        "    # Insert data into the collection\n",
        "    result = collection.insert_many(data)\n",
        "\n",
        "    # Print success message with the number of records inserted\n",
        "    print(f\"‚úÖ Inserted {len(result.inserted_ids)} records into '{collection_name}' collection in '{db_name}' database.\")\n"
      ],
      "metadata": {
        "id": "QqUNEg-xIZ8l"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine data from multiple sources (CSV, JSON, Excel, MongoDB)\n",
        "def extract_data_from_files_and_mongo():\n",
        "    # Example of reading from CSV, JSON, and Excel files (this should be adapted to your actual paths)\n",
        "    csv_data = pd.read_csv(\"/content/data/sports_data.csv\").to_dict(orient=\"records\")\n",
        "    json_data = json.load(open(\"/content/data/sports_data.json\", \"r\"))\n",
        "    excel_data = pd.read_excel(\"/content/data/sports_data.xlsx\").to_dict(orient=\"records\")\n",
        "    mongo_data = list(collection.find())\n",
        "\n",
        "    all_data = csv_data + json_data + excel_data + mongo_data\n",
        "    return all_data"
      ],
      "metadata": {
        "id": "ZgMpJ6RyO_vn"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main ETL pipeline function\n",
        "def etl_pipeline():\n",
        "    # MongoDB connection URI and database name\n",
        "    with open(\"/content/db_config.json\", \"r\") as f:\n",
        "        config = json.load(f)\n",
        "\n",
        "    mongo_uri = config.get(\"mongo_uri\")\n",
        "    db_name = \"sports_data\"  # Change as needed\n",
        "    collection_name = \"sports_data\"\n",
        "\n",
        "    # Extract data from different sources\n",
        "    csv_data = extract_csv(\"/content/sports_data.csv\")\n",
        "    json_data = extract_json(\"/content/sports_data.json\")\n",
        "    excel_data = extract_excel(\"/content/sports_data.xlsx\")\n",
        "    mongo_data = extract_mongodb(mongo_uri, db_name, collection_name)\n",
        "\n",
        "    # Combine all data into one list\n",
        "    all_data = csv_data + json_data + excel_data + mongo_data\n",
        "\n",
        "    # Transform the data\n",
        "    transformed_data = transform_data(all_data)\n",
        "\n",
        "    # Load transformed data into MongoDB\n",
        "    load_to_mongodb(mongo_uri, db_name, \"load_sports_data\", transformed_data)\n",
        "\n",
        "    # total records was\n",
        "    print(f\"‚úÖ Total records were {len(all_data)}\")\n"
      ],
      "metadata": {
        "id": "OQkJ_26IIemF"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# execute pipeline\n",
        "if __name__ == \"__main__\":\n",
        "    etl_pipeline()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uun7GnnaKKgd",
        "outputId": "97c0a5d8-74fc-4df1-e38e-8eb1982dfa6e"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ùØ Extracting CSV from /content/sports_data.csv...\n",
            "‚ùØ Extracting JSON from /content/sports_data.json...\n",
            "‚ùØ Extracting Excel from /content/sports_data.xlsx...\n",
            "‚ùØ Extracting data from MongoDB...\n",
            "‚ùØ Transforming data...\n",
            "‚ùØ Loading data into MongoDB collection 'load_sports_data'...\n",
            "‚úÖ Inserted 1287 records into 'load_sports_data' collection in 'sports_data' database.\n",
            "‚úÖ Total records were 1300\n"
          ]
        }
      ]
    }
  ]
}