{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install packages from requirements.txt\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAVs1L9679rv",
        "outputId": "d4ee5f14-df5a-4237-9b1d-69038c978163"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (2.2.2)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (0.3.11)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (4.11.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (0.13.2)\n",
            "Requirement already satisfied: faker in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (37.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->-r requirements.txt (line 1)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->-r requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->-r requirements.txt (line 1)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->-r requirements.txt (line 1)) (2025.1.31)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 2)) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 2)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 2)) (2025.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from kagglehub->-r requirements.txt (line 3)) (24.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from kagglehub->-r requirements.txt (line 3)) (6.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kagglehub->-r requirements.txt (line 3)) (4.67.1)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from pymongo->-r requirements.txt (line 4)) (2.7.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 5)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 5)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 5)) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 5)) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 5)) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 5)) (3.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 2)) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "EI8Q2WDu2Gd1"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import kagglehub\n",
        "from google.colab import files\n",
        "from pymongo import MongoClient\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import subprocess\n",
        "import faker\n",
        "import json\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "try:\n",
        "    result = subprocess.run([\"python3\", \"/content/load_to_db.py\"], check=True, capture_output=True, text=True)\n",
        "    print(\"‚úÖ Script executed successfully!\\n\")\n",
        "    print(result.stdout)\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(\"‚ùå Failed to run load_to_db.py\")\n",
        "    print(\"üîç Error Output:\\n\", e.stderr)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IF6khsRLGOjW",
        "outputId": "468da880-926a-4df9-c048-a162af8a1f07"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Script executed successfully!\n",
            "\n",
            "‚úÖ Connected to MongoDB!\n",
            "üìÇ Database: sports_data, Collection: sports_data\n",
            "üî¢ Existing Documents: 0\n",
            "‚úÖ Inserted 1400 records into 'sports_data' collection (1000 records with 400 duplicates).\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract data from CSV\n",
        "def extract_csv(file_path):\n",
        "    print(f\"‚ùØ Extracting CSV from {file_path}...\")\n",
        "    return pd.read_csv(file_path).to_dict(orient=\"records\")\n",
        "\n",
        "# Function to extract data from JSON\n",
        "def extract_json(file_path):\n",
        "    print(f\"‚ùØ Extracting JSON from {file_path}...\")\n",
        "    with open(file_path, \"r\") as f:\n",
        "        return json.load(f)\n",
        "\n",
        "# Function to extract data from Excel\n",
        "def extract_excel(file_path):\n",
        "    print(f\"‚ùØ Extracting Excel from {file_path}...\")\n",
        "    return pd.read_excel(file_path).to_dict(orient=\"records\")\n",
        "\n",
        "# Function to extract data from MongoDB collection\n",
        "def extract_mongodb(mongo_uri, db_name, collection_name):\n",
        "    print(f\"‚ùØ Extracting data from MongoDB...\")\n",
        "    client = MongoClient(mongo_uri)\n",
        "    db = client[db_name]\n",
        "    collection = db[collection_name]\n",
        "    return list(collection.find())"
      ],
      "metadata": {
        "id": "KO_sEkqdINIX"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to transform the data (e.g., cleaning or adding new fields)\n",
        "def transform_data(data):\n",
        "    print(f\"‚ùØ Transforming data...\")\n",
        "\n",
        "    # Remove duplicates based on Name & Country or Name & Sport\n",
        "    seen_records = set()\n",
        "    cleaned_data = []\n",
        "\n",
        "    for record in data:\n",
        "        name = record.get(\"Name\", \"\").strip()\n",
        "        country = record.get(\"Country\", \"\").strip()\n",
        "        sport = record.get(\"Sport\", \"\").strip()\n",
        "\n",
        "        # Create composite keys based on (Name & Country) or (Name & Sport)\n",
        "        if (name, country) not in seen_records and (name, sport) not in seen_records:\n",
        "            seen_records.add((name, country))\n",
        "            seen_records.add((name, sport))\n",
        "            cleaned_data.append(record)\n",
        "\n",
        "    # Apply transformations like cleaning, unit conversions, etc.\n",
        "    transformed_data = []\n",
        "    for record in cleaned_data:\n",
        "        # Data Cleaning: Handle missing values and erroneous values\n",
        "        if 'Sport' not in record or not record['Sport']:\n",
        "            record['Sport'] = 'Unknown'\n",
        "        if 'Team' not in record or not record['Team']:\n",
        "            record['Team'] = 'Unknown'\n",
        "\n",
        "        transformed_data.append(record)\n",
        "\n",
        "    return transformed_data"
      ],
      "metadata": {
        "id": "-OKW29rnIVHF"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load data into MongoDB\n",
        "def load_to_mongodb(mongo_uri, db_name, collection_name, data):\n",
        "    print(f\"‚ùØ Loading data into MongoDB collection '{collection_name}'...\")\n",
        "\n",
        "    # Connect to MongoDB\n",
        "    client = MongoClient(mongo_uri)\n",
        "\n",
        "    # Access the database (MongoDB will create it if it doesn't exist)\n",
        "    db = client[db_name]\n",
        "\n",
        "    # Access the collection (MongoDB will create it if it doesn't exist)\n",
        "    collection = db[collection_name]\n",
        "\n",
        "    # Insert data into the collection\n",
        "    result = collection.insert_many(data)\n",
        "\n",
        "    # Print success message with the number of records inserted\n",
        "    print(f\"‚úÖ Inserted {len(result.inserted_ids)} records into '{collection_name}' collection in '{db_name}' database.\")\n"
      ],
      "metadata": {
        "id": "QqUNEg-xIZ8l"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine data from multiple sources (CSV, JSON, Excel, MongoDB)\n",
        "def extract_data_from_files_and_mongo():\n",
        "    # Example of reading from CSV, JSON, and Excel files (this should be adapted to your actual paths)\n",
        "    csv_data = pd.read_csv(\"/content/data/sports_data.csv\").to_dict(orient=\"records\")\n",
        "    json_data = json.load(open(\"/content/data/sports_data.json\", \"r\"))\n",
        "    excel_data = pd.read_excel(\"/content/data/sports_data.xlsx\").to_dict(orient=\"records\")\n",
        "    mongo_data = list(collection.find())\n",
        "\n",
        "    all_data = csv_data + json_data + excel_data + mongo_data\n",
        "    return all_data"
      ],
      "metadata": {
        "id": "ZgMpJ6RyO_vn"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main ETL pipeline function\n",
        "def etl_pipeline():\n",
        "    # MongoDB connection URI and database name\n",
        "    with open(\"/content/db_config.json\", \"r\") as f:\n",
        "        config = json.load(f)\n",
        "\n",
        "    mongo_uri = config.get(\"mongo_uri\")\n",
        "    db_name = \"sports_data\"  # Change as needed\n",
        "    collection_name = \"sports_data\"\n",
        "\n",
        "    # Extract data from different sources\n",
        "    csv_data = extract_csv(\"/content/sports_data.csv\")\n",
        "    json_data = extract_json(\"/content/sports_data.json\")\n",
        "    excel_data = extract_excel(\"/content/sports_data.xlsx\")\n",
        "    mongo_data = extract_mongodb(mongo_uri, db_name, collection_name)\n",
        "\n",
        "    # Combine all data into one list\n",
        "    all_data = csv_data + json_data + excel_data + mongo_data\n",
        "\n",
        "    # Transform the data\n",
        "    transformed_data = transform_data(all_data)\n",
        "\n",
        "    # Load transformed data into MongoDB\n",
        "    load_to_mongodb(mongo_uri, db_name, \"load_sports_data\", transformed_data)\n",
        "\n",
        "    # total records was\n",
        "    print(f\"‚úÖ Total records were {len(all_data)}\")\n"
      ],
      "metadata": {
        "id": "OQkJ_26IIemF"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# execute pipeline\n",
        "if __name__ == \"__main__\":\n",
        "    etl_pipeline()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uun7GnnaKKgd",
        "outputId": "7cca88ab-0e4d-4422-f652-006103065542"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ùØ Extracting CSV from /content/sports_data.csv...\n",
            "‚ùØ Extracting JSON from /content/sports_data.json...\n",
            "‚ùØ Extracting Excel from /content/sports_data.xlsx...\n",
            "‚ùØ Extracting data from MongoDB...\n",
            "‚ùØ Transforming data...\n",
            "‚ùØ Loading data into MongoDB collection 'load_sports_data'...\n",
            "‚úÖ Inserted 1286 records into 'load_sports_data' collection in 'sports_data' database.\n",
            "‚úÖ Total records were 1700\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Method to query data from MongoDB and save it as CSV\n",
        "def export_data_to_csv(mongo_uri, db_name, collection_name, output_dir='/content/output', csv_file_name='final_cleaned_data.csv'):\n",
        "    print(f\"‚ùØ Querying data from MongoDB collection '{collection_name}' in database '{db_name}'...\")\n",
        "\n",
        "    # Establish connection to MongoDB\n",
        "    client = MongoClient(mongo_uri)\n",
        "    db = client[db_name]\n",
        "    collection = db[collection_name]\n",
        "\n",
        "    # Query all data from the collection\n",
        "    data_from_db = collection.find()\n",
        "\n",
        "    # Convert data to DataFrame\n",
        "    df = pd.DataFrame(list(data_from_db))\n",
        "\n",
        "    # Ensure the 'output' folder exists\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    # Path to save the CSV file\n",
        "    csv_file_path = os.path.join(output_dir, csv_file_name)\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    df.to_csv(csv_file_path, index=False)\n",
        "\n",
        "    print(f\"‚úÖ Data successfully saved to {csv_file_path}\")\n",
        "\n",
        "    # If you want to download the file from Colab to your local machine\n",
        "    files.download(csv_file_path)\n"
      ],
      "metadata": {
        "id": "tprNeXaoXWkY"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db_name = \"load_sports_data\"\n",
        "collection_name = \"sports_data\"\n",
        "with open(\"/content/db_config.json\", \"r\") as f:\n",
        "  config = json.load(f)\n",
        "\n",
        "  mongo_uri = config.get(\"mongo_uri\")\n",
        "\n",
        "# Call the method to export data from MongoDB collection to CSV\n",
        "export_data_to_csv(mongo_uri, db_name, collection_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "7GY8Uc44Xpzo",
        "outputId": "7acec9b5-720a-4196-dae8-da7374870dd4"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ùØ Querying data from MongoDB collection 'sports_data' in database 'load_sports_data'...\n",
            "‚úÖ Data successfully saved to /content/output/final_cleaned_data.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f717f1a2-23a6-4b73-8b1d-ca2711dc8b2f\", \"final_cleaned_data.csv\", 1)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}